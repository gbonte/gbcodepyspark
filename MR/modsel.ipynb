{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f79ec6bb",
   "metadata": {},
   "source": [
    "## INFOH515 Pyspark code\n",
    "## Author: Gianluca Bontempi\n",
    "## Pyspark implementation of the model selection algorithm in the INFOH515 slides \"Map-reduce analytics\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2763623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pwd\n",
    "import getpass\n",
    "import os\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, sum\n",
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# create an instance of SparkSession\n",
    "spark=SparkSession.builder.appName('s.com').getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ce59fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 6.32529461,  1.40410217,  1.84505492,  1.27428404, -1.15801998,\n",
       "        -0.77114336]),\n",
       " array([ 4.32475901,  0.34615021, -1.58390158, -0.47663391,  0.67023779,\n",
       "        -0.6931159 ])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.random.seed(1225)   \n",
    "\n",
    "\n",
    "Ntr=1500\n",
    "Nts=100\n",
    "N=Ntr+Nts\n",
    "n=5\n",
    "npartitions=5\n",
    "\n",
    "\n",
    "X= np.random.normal(loc=0, scale=1, size=N * n).reshape(N, n)\n",
    "Y=2+(X[:,0]**2)-3*X[:,n-1]+np.random.normal(loc=0, scale=0.1, size=N )\n",
    "Y=Y.reshape(N, 1)\n",
    "\n",
    "\n",
    "Xtr=X[:Ntr,]\n",
    "Ytr=Y[:Ntr,]\n",
    "Xts=X[Ntr:,]\n",
    "Yts=Y[Ntr:,]\n",
    "Ytr.shape=(Ntr,1)\n",
    "YX=np.hstack((Ytr,Xtr))\n",
    "vYts=np.var(Yts)\n",
    "YXrdd=sc.parallelize(YX,npartitions)\n",
    "\n",
    "YXrdd.take(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c38ae34",
   "metadata": {},
   "source": [
    "The dataset is split into npartitions and the same learning algorithm is applied to each partition.\n",
    "The test error of the learning algorithm trained on the first partition is compared with the test error of the averaging approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fe6fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rddCreateModels(iterator,modlist):\n",
    "    listm=[]\n",
    "    data=np.array(list(iterator))\n",
    "    X = data[:, 1:]\n",
    "    Y=data[:, 0]\n",
    "    for mod in modlist:     \n",
    "        #data=np.array(list(iterator))\n",
    "        m=mod.fit(X,Y)  \n",
    "        listm=listm+[m]\n",
    "        \n",
    "    return listm\n",
    "def rddUseModel(iterator,Xts):\n",
    "    rfit=list(iterator)[0]\n",
    "    #return [pow(Yts-rfit.predict(Xts),2)]\n",
    "    return [rfit.predict(Xts)]\n",
    "\n",
    "def rddApplyMean(D,axis=0):\n",
    "    if (axis==0): # column\n",
    "        N=D.count()\n",
    "        return(D.reduce(lambda x,y:x+y)/N)\n",
    "\n",
    "    if (axis==1): #row\n",
    "        return(rddArr(D.map(lambda x:mean(x))))\n",
    "    \n",
    "\n",
    "ncores=-1\n",
    "\n",
    "mregr0= DecisionTreeRegressor(max_depth=15)\n",
    "mregr1= RandomForestRegressor(n_estimators=2*nT,max_depth=10,n_jobs=ncores)\n",
    "mregr2= AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),\n",
    "                          n_estimators=100)\n",
    "mregr3= KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "M2=YXrdd.mapPartitions(lambda x: rddCreateModels(x,[mregr0,mregr1,mregr2,mregr3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa5a43",
   "metadata": {},
   "source": [
    "## Prediction of the candidate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec02c82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMSE model 1= 0.017948071981141556\n",
      "NMSE model 2= 0.026728533521305078\n",
      "NMSE model 3= 0.06749214982627325\n",
      "NMSE model 4= 0.09283371549791214\n"
     ]
    }
   ],
   "source": [
    "def rddUseModel(iterator,Xts):\n",
    "    listpred=[]\n",
    "    rfit=list(iterator)\n",
    "    cnt=0\n",
    "    for r in rfit:\n",
    "        pred=r.predict(Xts)\n",
    "        listpred=listpred+[(cnt,pred)]\n",
    "        cnt=cnt+1\n",
    "    return listpred\n",
    "\n",
    "Yhat1=rddApplyMean(M2.mapPartitions(lambda x: rddUseModel(x,Xts)).filter(lambda x: x[0]==0).map(lambda x: x[1]))\n",
    "Yhat2=rddApplyMean(M2.mapPartitions(lambda x: rddUseModel(x,Xts)).filter(lambda x: x[0]==1).map(lambda x: x[1]))\n",
    "Yhat3=rddApplyMean(M2.mapPartitions(lambda x: rddUseModel(x,Xts)).filter(lambda x: x[0]==2).map(lambda x: x[1]))\n",
    "Yhat4=rddApplyMean(M2.mapPartitions(lambda x: rddUseModel(x,Xts)).filter(lambda x: x[0]==3).map(lambda x: x[1]))\n",
    "errhat1=Yts.ravel()-Yhat1.ravel()\n",
    "print(\"NMSE model 1=\", np.mean(pow(errhat1,2))/vYts)\n",
    "\n",
    "errhat2=Yts.ravel()-Yhat2.ravel()\n",
    "print(\"NMSE model 2=\",np.mean(pow(errhat2,2))/vYts)\n",
    "\n",
    "errhat3=Yts.ravel()-Yhat3.ravel()\n",
    "print(\"NMSE model 3=\",np.mean(pow(errhat3,2))/vYts)\n",
    "\n",
    "\n",
    "errhat4=Yts.ravel()-Yhat4.ravel()\n",
    "print(\"NMSE model 4=\",np.mean(pow(errhat4,2))/vYts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098c47db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
