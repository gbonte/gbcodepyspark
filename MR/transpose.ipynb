{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9bbe922-ca09-4540-a8d4-af26b025a5aa",
   "metadata": {},
   "source": [
    "## INFOH515 Pyspark code\n",
    "## Author: Gianluca Bontempi\n",
    "## Pyspark implementation of the matrix transpose \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baa8908",
   "metadata": {},
   "source": [
    "Let us consider a least-squares regression problem with a single output target Y and n input variables X,..., Xn.\n",
    "\n",
    "Suppose that the dataset (made of N observations) is stored in a horizontal format, i.e. the first row corresponds to the output Y and the following n rows correspond to the n inputs.\n",
    "\n",
    "$$0, y_1, ..., y_N\\\\\n",
    "1, x_{11}, ..., x_{N1}\\\\\n",
    ".. . .\\\\\n",
    "n, x_{1n}. ..., x_{Nn}\n",
    "$$\n",
    "\n",
    "Write a map-reduce pseudo-code to transpose the matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36153eb3-64a8-4635-a007-23928990b40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/18 11:30:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pwd\n",
    "# Disable warnings, set Matplotlib inline plotting and load Pandas package\n",
    "import numpy as np\n",
    "import getpass\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# create an instance of SparkSession\n",
    "spark=SparkSession.builder.appName('s.com').getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e78cdf50-c932-4733-9f42-0585331ee818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order(x):\n",
    "    x1=x[1]\n",
    "    n=int(len(x1)/2)\n",
    "    xx=np.zeros(n)\n",
    "    for i in range(n):\n",
    "        xx[int(x1[2*i])]=x1[2*i+1]\n",
    "    return((x[0],xx))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a11f3a-5d2b-405f-a541-1b5d1fe7ccfb",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ee6489f-a6d8-4cfe-83e0-ee8307fe2504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 1.0, -1.0, 0.0, 12.0],\n",
       " [1.0, 2.0, -3.0, 14.0, 14.0],\n",
       " [2.0, 3.0, -5.0, 16.0, 16.0],\n",
       " [3.0, 4.0, -0.0, 10.0, 10.0],\n",
       " [4.0, 1.0, -1.0, 12.0, 12.0],\n",
       " [5.0, 2.0, -5.0, 16.0, 16.0]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset = sc.textFile(\"DXY\").map(lambda x : x.split(\",\")).map(lambda x : [float(i) for i in x])\n",
    "Dataset.collect()\n",
    "#the first column represents the column in the transpose matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f32f5-5193-4d77-a417-2a4ebf7cad59",
   "metadata": {},
   "source": [
    "#### map (x)-> (row,(col,x[row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f374f2e-cdca-4732-b425-ce6d54538704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, (0.0, 1.0)),\n",
       " (1, (0.0, -1.0)),\n",
       " (2, (0.0, 0.0)),\n",
       " (3, (0.0, 12.0)),\n",
       " (0, (1.0, 2.0)),\n",
       " (1, (1.0, -3.0)),\n",
       " (2, (1.0, 14.0)),\n",
       " (3, (1.0, 14.0)),\n",
       " (0, (2.0, 3.0)),\n",
       " (1, (2.0, -5.0)),\n",
       " (2, (2.0, 16.0)),\n",
       " (3, (2.0, 16.0)),\n",
       " (0, (3.0, 4.0)),\n",
       " (1, (3.0, -0.0)),\n",
       " (2, (3.0, 10.0)),\n",
       " (3, (3.0, 10.0)),\n",
       " (0, (4.0, 1.0)),\n",
       " (1, (4.0, -1.0)),\n",
       " (2, (4.0, 12.0)),\n",
       " (3, (4.0, 12.0)),\n",
       " (0, (5.0, 2.0)),\n",
       " (1, (5.0, -5.0)),\n",
       " (2, (5.0, 16.0)),\n",
       " (3, (5.0, 16.0))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tDataset=Dataset.flatMap(lambda x : [(i-1,((x[0]),x[i])) for i in range(1,len(x))])\n",
    "# i-1 is the key and represents the row in the transpose matrix\n",
    "# x[0] is the column in the transposed matrix\n",
    "# x[i] is the element in position x[row,col] in the transpose matrix\n",
    "\n",
    "\n",
    "tDataset.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30ce1c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, (0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0, 1.0, 5.0, 2.0)),\n",
       " (2, (0.0, 0.0, 1.0, 14.0, 2.0, 16.0, 3.0, 10.0, 4.0, 12.0, 5.0, 16.0)),\n",
       " (1, (0.0, -1.0, 1.0, -3.0, 2.0, -5.0, 3.0, -0.0, 4.0, -1.0, 5.0, -5.0)),\n",
       " (3, (0.0, 12.0, 1.0, 14.0, 2.0, 16.0, 3.0, 10.0, 4.0, 12.0, 5.0, 16.0))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tDataset=tDataset.reduceByKey(lambda a,b: (a+b))\n",
    "\n",
    "# reduce join the lists associated to the same row\n",
    "tDataset.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd98501-066d-48a9-9ef8-ab86fdfd7a0e",
   "metadata": {},
   "source": [
    "#### Order the elements according to the column order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a791bf57-30b4-4b61-813e-6a5c96fa096b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, array([1., 2., 3., 4., 1., 2.])),\n",
       " (1, array([-1., -3., -5., -0., -1., -5.])),\n",
       " (2, array([ 0., 14., 16., 10., 12., 16.])),\n",
       " (3, array([12., 14., 16., 10., 12., 16.]))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tDataset2=tDataset.map(lambda x : order(x)).sortByKey()\n",
    "tDataset2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b75d0f1-a9d8-4325-b5f3-5c95255b8b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca4312d-d990-4533-a2b6-68407c20b2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4991af2a-c6a8-4b17-b5e4-17f35a553929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
