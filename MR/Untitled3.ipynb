{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b3a3604",
   "metadata": {},
   "source": [
    "## INFOH515 Pyspark code\n",
    "## Author: Gianluca Bontempi\n",
    "## Pyspark implementation of the bagging algorithm in the INFOH515 slides \"Map-reduce analytics\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea75e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/17 16:37:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/17 16:37:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/03/17 16:37:13 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/03/17 16:37:13 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "25/03/17 16:37:13 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "25/03/17 16:37:13 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "25/03/17 16:37:13 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pwd\n",
    "import getpass\n",
    "import os\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, sum\n",
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# create an instance of SparkSession\n",
    "spark=SparkSession.builder.appName('s.com').getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf8d211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(1225)   \n",
    "\n",
    "n=20 # number of features\n",
    "\n",
    "\n",
    "\n",
    "Ntr=5000\n",
    "Nts=1000\n",
    "N=Ntr+Nts\n",
    "n=8\n",
    "X= np.random.normal(loc=0, scale=1, size=N * n).reshape(N, n)\n",
    "X=np.concatenate((np.ones((N,1)),X), axis=1)\n",
    "Y=2+X[:,1]-3*X[:,7]+np.random.normal(loc=0, scale=0.1, size=N )\n",
    "Y=Y.reshape(N, 1)\n",
    "\n",
    "\n",
    "Xtr=X[:Ntr,]\n",
    "Ytr=Y[:Ntr,]\n",
    "Xts=X[Ntr:,]\n",
    "Yts=Y[Ntr:,]\n",
    "Ytr.shape=(Ntr,1)\n",
    "YX=np.hstack((Ytr,Xtr))\n",
    "vYts=np.var(Yts)\n",
    "YXrdd=sc.parallelize(YX,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3c6f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rddCreateModels(iterator,mod):\n",
    "\n",
    "    data=np.array(list(iterator))\n",
    "    X = data[:, 1:]\n",
    "    Y=data[:, 0]\n",
    "    m=mod.fit(X,Y)  \n",
    "    return [m]\n",
    "\n",
    "def rddUseModel(iterator,Xts):\n",
    "    rfit=list(iterator)[0]\n",
    "    #return [pow(Yts-rfit.predict(Xts),2)]\n",
    "    return [rfit.predict(Xts)]\n",
    "\n",
    "def rddApplyMean(D,axis=0):\n",
    "    if (axis==0): # column\n",
    "        N=D.count()\n",
    "        return(D.reduce(lambda x,y:x+y)/N)\n",
    "\n",
    "    if (axis==1): #row\n",
    "        return(rddArr(D.map(lambda x:mean(x))))\n",
    "    \n",
    "nT=1000\n",
    "mD=15\n",
    "ncores=3\n",
    "\n",
    "mregr0= RandomForestRegressor(n_estimators=nT,max_depth=mD,n_jobs=ncores)\n",
    "M2=YXrdd.mapPartitions(lambda x: rddCreateModels(x,mregr0))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
